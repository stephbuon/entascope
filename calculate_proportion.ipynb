{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def count_words(clean_data):\n",
    "    ngrams_dict = {}\n",
    "    for ngram in clean_data:\n",
    "        if ngram in ngrams_dict:\n",
    "            ngrams_dict[ngram] += 1\n",
    "        else:\n",
    "            ngrams_dict[ngram] = 1\n",
    "    \n",
    "    return ngrams_dict\n",
    "\n",
    "def correct_entity_labels(named_entites):\n",
    "    # d- and r- are recategorized to represent democrat or republican\n",
    "\n",
    "    coronavirus = re.compile(r'covid|coronavirus|vaccine|omicron|delta|vaccinat|vaxx|pandemic|mask|\\bncov\\b', re.IGNORECASE)\n",
    "    events = re.compile(r'twitter .*|mandate|^tts$', re.IGNORECASE)\n",
    "    vaccines = re.compile(r'pfizer|moderna|johnson', re.IGNORECASE)\n",
    "    people = re.compile(r'warren|trump|psaki|palin|fauci|santa claus|desantis|cuomo|newsom|de blasio|biden|horak|mayorkas|michelle|kilgore|murphy|walensky', re.IGNORECASE)\n",
    "    organizations = re.compile(r'white house covid-19 team|glaxosmithkline|office of vaccines research and review|front line covid-19 critical care alliance|house select subcommittee on the coronavirus crisis|^d-|^r-|refinitiv lipper|england patriots|scarlet.*knights|astros|task(.*)force|democrat|republican|delta air|cornell|mckesson', re.IGNORECASE) \n",
    "    gpe_locations = re.compile(r'eswatini|seattle|america| u\\.s\\.|beijing|louisiana|michigan|saxony', re.IGNORECASE)\n",
    "    fac = re.compile(r'flightaware|allegiant stadium|covid data tracker|long covid clinic at|vaccine adverse event reporting system|international vaccine access center', re.IGNORECASE)\n",
    "    laws = re.compile(r'E.*O.*2021-18|nuremberg code|arizona constitution|Civil Rights Act', re.IGNORECASE)\n",
    "\n",
    "    products = re.compile(r'hunger games', re.IGNORECASE)\n",
    "\n",
    "    named_entites['entity_text'] = named_entites['entity_text'].str.lower()\n",
    "    named_entites['entity_text'] = named_entites['entity_text'].astype(str)\n",
    "\n",
    "    named_entites['entity_label'] = named_entites.apply(lambda row: 'EVENT' if coronavirus.search(row['entity_text']) else row['entity_label'] , axis=1)\n",
    "    named_entites['entity_label'] = named_entites.apply(lambda row: 'ORG' if organizations.search(row['entity_text']) else row['entity_label'] , axis=1)\n",
    "    named_entites['entity_label'] = named_entites.apply(lambda row: 'ORG' if vaccines.search(row['entity_text']) else row['entity_label'] , axis=1)\n",
    "    named_entites['entity_label'] = named_entites.apply(lambda row: 'EVENT' if events.search(row['entity_text']) else row['entity_label'] , axis=1)\n",
    "    named_entites['entity_label'] = named_entites.apply(lambda row: 'PERSON' if people.search(row['entity_text']) else row['entity_label'] , axis=1)\n",
    "    named_entites['entity_label'] = named_entites.apply(lambda row: 'GPE' if gpe_locations.search(row['entity_text']) else row['entity_label'] , axis=1)\n",
    "    named_entites['entity_label'] = named_entites.apply(lambda row: 'FAC' if fac.search(row['entity_text']) else row['entity_label'] , axis=1)\n",
    "    named_entites['entity_label'] = named_entites.apply(lambda row: 'LAW' if laws.search(row['entity_text']) else row['entity_label'] , axis=1)\n",
    "\n",
    "    named_entites['entity_label'] = named_entites.apply(lambda row: 'PRODUCT' if products.search(row['entity_text']) else row['entity_label'] , axis=1)\n",
    "\n",
    "    return named_entites\n",
    "\n",
    "\n",
    "def clean_entities(df, source):\n",
    "    df['entity_text'] = df['entity_text'].astype(str)\n",
    "\n",
    "    df['entity_text'] = df['entity_text'].str.lower()\n",
    "\n",
    "    df['entity_text'] = df['entity_text'].apply(lambda x: re.sub(r'^the ', '', x))\n",
    "    df['entity_text'] = df['entity_text'].apply(lambda x: re.sub(r'\\'s', '', x))\n",
    "    df['entity_text'] = df['entity_text'].apply(lambda x: re.sub(r's\\'', '', x))\n",
    "    df['entity_text'] = df['entity_text'].apply(lambda x: re.sub(r'’s', '', x))\n",
    "    df['entity_text'] = df['entity_text'].apply(lambda x: re.sub(r's’', '', x))\n",
    "    df['entity_text'] = df['entity_text'].apply(lambda x: re.sub(r'\\\"', '', x))\n",
    "\n",
    "    df['entity_text'] = df['entity_text'].apply(lambda x: re.sub(r'covid.*19', 'covid-19', x))\n",
    "    df['entity_text'] = df['entity_text'].apply(lambda x: re.sub(r'covid.*19 -', 'covid-19', x))\n",
    "\n",
    "    df['entity_text'] = df['entity_text'].apply(lambda x: re.sub(r'rain due to covid', 'covid-19', x))\n",
    "\n",
    "    remove_news_outlets = re.compile(r'fox|llc|abc|associated press|^cbs$|reuters|cnn|\\bap\\b|npr|nbc|buzzfeed|tribune|boston globe|bloomberg|vox|washington post|huffpost|new york post|new york times|usa today')\n",
    "    f = df['entity_text'].str.contains(remove_news_outlets)\n",
    "    df = df[~f]\n",
    "\n",
    "    remove_image_credits = re.compile(r'photo|getty|flickr|istock|^afp$')\n",
    "    f = df['entity_text'].str.contains(remove_image_credits)\n",
    "    df = df[~f]\n",
    "\n",
    "    remove_junk = re.compile(r'nan|file|^quote$|^quotes$')\n",
    "    f = df['entity_text'].str.contains(remove_junk)\n",
    "    df = df[~f]\n",
    "\n",
    "    remove_fox_ads = re.compile(r'factset|mutual fund| lipper|^app$')\n",
    "    f = df['entity_text'].str.contains(remove_fox_ads)\n",
    "    df = df[~f]\n",
    "\n",
    "    if source == 'NPR':\n",
    "        glyphs = re.compile(r'�')\n",
    "        f = df['entity_text'].str.contains(glyphs)\n",
    "        df = df[~f]\n",
    "\n",
    "        remove_reporters = re.compile(r'rick bowmer|alex brandon|john minchillo|marta lavandier|daniel wood|jonathan franklin|bill chappell|moffett|scott neuman|matthew s. schwartz|mary altaffer|sarah silbiger|lynne sladky|ethan miller|scott hensley|ed jones|scott heins|vanessa romo|rachel treisman|jaclyn diaz')\n",
    "        f = df['entity_text'].str.contains(remove_reporters)\n",
    "        df = df[~f]\n",
    "\n",
    "    if source == 'FOX':\n",
    "        remove_reporters = re.compile(r'evan vucci|^michelle$|michael lee|kyle morris|andrew mark miller|austin')\n",
    "        f = df['entity_text'].str.contains(remove_reporters)\n",
    "        df = df[~f]\n",
    "        names = re.compile(r'abbott')\n",
    "        df['entity_label'] = df.apply(lambda row: 'PERSON' if names.search(row['entity_text']) else row['entity_label'] , axis=1)\n",
    "\n",
    "\n",
    "    df['entity_text'] = df['entity_text'].str.strip()\n",
    "\n",
    "    df = df.drop(df[df['entity_text'].str.len() < 2].index)\n",
    "\n",
    "    return df\n",
    "\n",
    "def to_upper(row):\n",
    "    if len(row) <= 3:\n",
    "        return row.upper()\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "def title_case(row):\n",
    "    if len(row) > 3:\n",
    "        return row.title()\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "def correct_case(df):\n",
    "    df['entity_text'] = df['entity_text'].apply(to_upper)\n",
    "    df['entity_text'] = df['entity_text'].apply(title_case)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def find_proportion(df):\n",
    "    return (df['count'] / df['count'].sum()) * 100\n",
    "\n",
    "\n",
    "def export_measurements(df, ts, filter_by, source):\n",
    "    df = correct_entity_labels(df)\n",
    "    df = clean_entities(df, source)\n",
    "\n",
    "    try:\n",
    "        df.drop('Unnamed: 0', axis=1, inplace=True) \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    df = df[df['entity_label'] == filter_by].copy() # temp -- to find proportion of PERSONs for all PERSONs\n",
    "\n",
    "    df['source'] = source\n",
    "    df['count'] = df.groupby('entity_text')['entity_text'].transform('count')\n",
    "\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    df['proportion'] = find_proportion(df)\n",
    "\n",
    "    #df = df[df['entity_label'] == filter_by].copy() # for over all proportion, would need to filter for just twitter that is person\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    df = correct_case(df)\n",
    "    df.sort_values(by = ['proportion'], inplace = True, ascending = False)\n",
    "\n",
    "    if not os.path.exists('/home/stephbuon/projects/entascope/results/' + ts):\n",
    "        os.mkdir('/home/stephbuon/projects/entascope/results/' + ts)\n",
    "\n",
    "    df.to_csv('/home/stephbuon/projects/entascope/results/' + ts + '/' + source + '_' + filter_by + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_labels = ['PERSON', 'EVENT', 'ORG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = '12-27-2021'\n",
    "npr_ne = pd.read_csv('/home/stephbuon/projects/entascope/scraped_pages/' + ts + '/' + 'named_entities_NPR_' + ts +'.csv')\n",
    "\n",
    "for label in ent_labels:\n",
    "    export_measurements(npr_ne, ts, label, 'NPR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = '12-27-2021'\n",
    "fox_ne = pd.read_csv('/home/stephbuon/projects/entascope/scraped_pages/' + ts + '/' + 'named_entities_FOX_' + ts + '.csv')\n",
    "\n",
    "for label in ent_labels:\n",
    "    export_measurements(fox_ne, ts, label, 'FOX')#, 'EVENT', 'FOX')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80e230aa2106b1d0405f482c44fb2bb5a0747aecf059ed39fae9051ddf6d7244"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
