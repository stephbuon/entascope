{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# for url in url csv:\n",
    "# get the URL and the article_id, source\n",
    "\n",
    "#page_content = BeautifulSoup(response.text, 'html.parser')\n",
    "#for paragraph in page_content.findAll('p'):\n",
    "#paragraph = list(paragraph.stripped_strings)\n",
    "#for sentence in paragraph: \n",
    "\n",
    "\n",
    "def extract_article_text(citations):\n",
    "    citations = pd.read_csv(citations)\n",
    "\n",
    "    for index, row in citations.iterrows():\n",
    "        url = row['url']\n",
    "        article_id = row['article_id']\n",
    "        source = row['source']\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            page_content = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "            for paragraph in page_content.findAll('p'):\n",
    "                paragraph = list(paragraph.stripped_strings)\n",
    "\n",
    "                for sentence in paragraph:\n",
    "                    pass\n",
    "\n",
    "        except Exception as response_exception:\n",
    "            print(response_exception) # make this into a log\n",
    "            print(url)\n",
    "            print(article_id)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def export_article_text():\n",
    "    pass\n",
    "\n",
    "\n",
    "def article_content_scraper():\n",
    "    pass\n",
    "\n",
    "\n",
    "#    named_entites = pd.DataFrame(\n",
    "#        {'entity_label': out.keys(), 'entity_text': out.values() } )\n",
    "            \n",
    "#    named_entites = named_entites.explode('entity_text')\n",
    "#    named_entites = correct_entity_labels(named_entites)\n",
    "\n",
    "#    if not os.path.isfile(export_path + ts + '/' + 'named_entities_' + source + '_' + ts + '.csv'):\n",
    "#        named_entites.to_csv(export_path + ts + '/' + 'named_entities_' + source + '_' + ts + '.csv')\n",
    "#    else:\n",
    "#        old_named_entities = pd.read_csv(export_path + ts + '/' + 'named_entities_' + source + '_' + ts + '.csv')\n",
    "#        named_entites = pd.concat([named_entites, old_named_entities], ignore_index = True)\n",
    "\n",
    "#        named_entites.to_csv(export_path + ts + '/' + 'named_entities_' + source + '_' + ts + '.csv', index = False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
