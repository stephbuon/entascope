{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for url in url csv:\n",
    "# get the URL and the article_id, source\n",
    "\n",
    "#response = requests.get(url)\n",
    "#page_content = BeautifulSoup(response.text, 'html.parser')\n",
    "#for paragraph in page_content.findAll('p'):\n",
    "#paragraph = list(paragraph.stripped_strings)\n",
    "#for sentence in paragraph: \n",
    "\n",
    "\n",
    "#    named_entites = pd.DataFrame(\n",
    "#        {'entity_label': out.keys(), 'entity_text': out.values() } )\n",
    "            \n",
    "#    named_entites = named_entites.explode('entity_text')\n",
    "#    named_entites = correct_entity_labels(named_entites)\n",
    "\n",
    "#    if not os.path.isfile(export_path + ts + '/' + 'named_entities_' + source + '_' + ts + '.csv'):\n",
    "#        named_entites.to_csv(export_path + ts + '/' + 'named_entities_' + source + '_' + ts + '.csv')\n",
    "#    else:\n",
    "#        old_named_entities = pd.read_csv(export_path + ts + '/' + 'named_entities_' + source + '_' + ts + '.csv')\n",
    "#        named_entites = pd.concat([named_entites, old_named_entities], ignore_index = True)\n",
    "\n",
    "#        named_entites.to_csv(export_path + ts + '/' + 'named_entities_' + source + '_' + ts + '.csv', index = False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
